{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8044b04a",
   "metadata": {},
   "source": [
    "# üéµ Event Recommender ‚Äì Content‚ÄëBased Filtering Demo\n",
    "A self‚Äëcontained walkthrough that loads **`merged_events_clean.csv`**, builds a TF‚ÄëIDF‚ÄØ+‚ÄØmetadata feature matrix, fits a cosine‚Äësimilarity Nearest‚ÄëNeighbors model, and exposes a helper `recommend()`‚ÄØfunction.\n",
    "\n",
    "*Python¬†3 ¬∑ Pandas ¬∑ Scikit‚Äëlearn ¬∑ Joblib*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749ac5b",
   "metadata": {},
   "source": [
    "## 0. Setup & Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18efaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import hstack\n",
    "import joblib\n",
    "print('Libraries imported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f4a31",
   "metadata": {},
   "source": [
    "## 1. Load & Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6696aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = Path('merged_events_clean - merged_events_clean.csv')  # adjust if needed\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce89a8",
   "metadata": {},
   "source": [
    "## 2. Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date/time\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df['time'] = pd.to_datetime(df['time'], format='%H:%M', errors='coerce').dt.time\n",
    "\n",
    "# Price columns\n",
    "df['price_adv']  = pd.to_numeric(df['in advance'], errors='coerce')\n",
    "df['price_door'] = pd.to_numeric(df['cover'], errors='coerce')\n",
    "\n",
    "mid_price = df[['price_adv', 'price_door']].stack().median()\n",
    "df['price_adv'].fillna(df['price_door'], inplace=True)\n",
    "df['price_door'].fillna(df['price_adv'], inplace=True)\n",
    "df[['price_adv', 'price_door']] = df[['price_adv', 'price_door']].fillna(mid_price)\n",
    "\n",
    "# Location (city + district)\n",
    "loc_extracted = df['place'].fillna('').str.extract(r'^(?P<city>[^ ]+)\\s*(?P<gu>[^ ]+)?')\n",
    "df['loc_sigu'] = loc_extracted['city'].fillna('') + ' ' + loc_extracted['gu'].fillna('')\n",
    "df.loc[df['loc_sigu'].str.strip() == '', 'loc_sigu'] = 'unknown'\n",
    "\n",
    "df[['date','time','price_adv','price_door','loc_sigu']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5486d",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "### 3‚Äë1. TF‚ÄëIDF for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b98aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = (\n",
    "    df['content'].fillna('') + ' ' +\n",
    "    df['place'].fillna('')   + ' ' +\n",
    "    df['loc_sigu'].fillna('')\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=10_000,\n",
    "                        ngram_range=(1,2),\n",
    "                        min_df=3,\n",
    "                        stop_words='english')\n",
    "X_text = tfidf.fit_transform(text_corpus)\n",
    "X_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93046132",
   "metadata": {},
   "source": [
    "### 3‚Äë2. Numeric & Categorical metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f01694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['price_adv', 'price_door']\n",
    "cat_cols = ['loc_sigu']\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', MinMaxScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "X_meta = pre.fit_transform(df)\n",
    "X_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba627e2",
   "metadata": {},
   "source": [
    "### 3‚Äë3. Combine & Build Final Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "X_all = hstack([X_text, X_meta]).tocsr()\n",
    "X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac9589",
   "metadata": {},
   "source": [
    "## 4. Fit Cosine Nearest‚ÄëNeighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(metric='cosine', n_neighbors=20, n_jobs=-1)\n",
    "knn.fit(X_all)\n",
    "\n",
    "# Persist everything\n",
    "MODEL_DIR = Path('model')\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "joblib.dump({'tfidf': tfidf, 'pre': pre, 'knn': knn, 'df': df}, MODEL_DIR/'recommender.joblib')\n",
    "print('Model saved to', MODEL_DIR/'recommender.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4473b3",
   "metadata": {},
   "source": [
    "## 5. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad5077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = joblib.load(MODEL_DIR/'recommender.joblib')\n",
    "\n",
    "def encode_query(q: dict):\n",
    "    txt_vec = job['tfidf'].transform([q.get('keywords','')])\n",
    "    meta_df = pd.DataFrame([{\n",
    "        'price_adv' : q.get('price_max', mid_price),\n",
    "        'price_door': q.get('price_max', mid_price),\n",
    "        'loc_sigu'  : q.get('location', 'unknown')\n",
    "    }])\n",
    "    meta_vec = job['pre'].transform(meta_df)\n",
    "    return hstack([txt_vec, meta_vec])\n",
    "\n",
    "def recommend(query: dict, top_k=5):\n",
    "    q_vec = encode_query(query)\n",
    "    dist, idx = job['knn'].kneighbors(q_vec, n_neighbors=top_k)\n",
    "    recs = job['df'].iloc[idx[0]].copy()\n",
    "    recs['score'] = 1 - dist[0]\n",
    "    return recs[['link','content','place','date','time','price_adv','price_door','score']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c94fc",
   "metadata": {},
   "source": [
    "## 6. Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = {\n",
    "    'keywords': 'psychedelic rock live',\n",
    "    'price_max': 35000,\n",
    "    'location': 'ÏÑúÏö∏ ÎßàÌè¨Íµ¨'\n",
    "}\n",
    "\n",
    "recommend(sample_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d960b4dc",
   "metadata": {},
   "source": [
    "## 7. (Optional) FastAPI Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a75f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run this cell separately (e.g., save as api.py) and launch with:\n",
    "\n",
    "    uvicorn api:app --host 0.0.0.0 --port 8000\n",
    "\"\"\"\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI()\n",
    "model = joblib.load('model/recommender.joblib')\n",
    "\n",
    "class Query(BaseModel):\n",
    "    keywords:  str = ''\n",
    "    price_max: float | None = None\n",
    "    location:  str = ''\n",
    "\n",
    "@app.post('/recommend')\n",
    "def rec_api(q: Query, top_k:int=5):\n",
    "    res = recommend(q.dict(), top_k=top_k)\n",
    "    return res.to_dict(orient='records')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     uvicorn.run(app, host='0.0.0.0', port=8000)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
